{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_recognition_using_arcface.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIgIAdGL+tmAGfBhbus8G4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayan0506/Face-Recognition-pipeline-using-SOTA-ArcFace/blob/main/Face_recognition_using_arcface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XeOuxgY_2eK"
      },
      "source": [
        "# **Face recognition Pipeline design using arcface**\n",
        "\n",
        "This notebook is inspired from the paper [ArcFace: Additive Angular Margin Loss for Deep Face Recognition](https://arxiv.org/pdf/1801.07698v3.pdf)\n",
        "\n",
        "Git repo: [Insightface_Pytorch](https://github.com/TreB1eN/InsightFace_Pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIXqdxd086ho"
      },
      "source": [
        "**Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uxoiSwdlf4j",
        "outputId": "030ce1e7-82b3-4e4d-e1e6-ec5a45587224"
      },
      "source": [
        "# install tensorboardX\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 28.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 33.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 28.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 28.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 30.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 26.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 26.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 25.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.1.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axuU73KwA3cC"
      },
      "source": [
        "## **Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db0Lbuh2FBik"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# data pipeline\n",
        "# helps to create dict where, use keys as atribute\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "from torchvision import transforms as trans\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image, ImageFile\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ensures loading truncated images \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# model build\n",
        "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from collections import namedtuple\n",
        "import math\n",
        "import pdb\n",
        "\n",
        "# model training\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch import optim\n",
        "import model\n",
        "from tqdm import tqdm\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh4XQrH2ZNJk"
      },
      "source": [
        "## **Mount Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLIwEiZwFGcW",
        "outputId": "72de2b46-5bdd-43aa-d5c5-ce7f1c05cce4"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5FmbF9u8BqH"
      },
      "source": [
        "## **Environment Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw_kTVAt8S9U"
      },
      "source": [
        "**Check GPU utilization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMZ047Z8BId",
        "outputId": "850203b4-2ea0-4567-c8ad-0872ce40650e"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Running on device: {device}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7e38u2g8muB",
        "outputId": "39204e74-d78b-46ea-a5ee-47dfcf94c7a8"
      },
      "source": [
        "print(f'Device info\\n{torch.cuda.get_device_properties(0)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device info\n",
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lclnCGEuaLaI"
      },
      "source": [
        "## **Dataset Load**\n",
        "\n",
        "Load the avengers face dataset\n",
        "* Source: [Kaggle](https://www.kaggle.com/rawatjitesh/avengers-face-recognition)\n",
        "* Drive link: [Dataset](https://drive.google.com/drive/folders/1VYuEXVOzUtd7fOaaLv7oW4YwGYbvh80w?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AhUFYdbLcpQ"
      },
      "source": [
        "**Defining Configuration Dictionary, which will contain the important metadata regarding the ML pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK2Y2s80LnMr"
      },
      "source": [
        "# config edict dictionary initialize\n",
        "config = edict()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8qzf3Ijgyql"
      },
      "source": [
        "# configure device\n",
        "config.device = device"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiOnY2VjZaUl"
      },
      "source": [
        "# avengers face dataset path\n",
        "dataset_path = \"/content/gdrive/MyDrive/Kaggle Avengers face dataset/Marvels_face_dataset\"\n",
        "# add dataset path to config\n",
        "config.imgs_folder = dataset_path"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZcH2SnP5cjZ"
      },
      "source": [
        "**Configure input image size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDKDbUb66w0e"
      },
      "source": [
        "config.input_size = (112,112)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liiAB1D0dT3Y"
      },
      "source": [
        "**Create train dataset from the folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0C2fG76cmxd"
      },
      "source": [
        "def get_train_dataset(config):\n",
        "  # create torchvision transforms object for train data\n",
        "  train_transform = trans.Compose([\n",
        "                                   trans.RandomHorizontalFlip(), # random horizonttal flip of faces\n",
        "                                   trans.ToTensor(), # convert img to torch tensor\n",
        "                                   trans.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]), # normalize\n",
        "                                   trans.Resize(config.input_size, interpolation=trans.InterpolationMode.BICUBIC)\n",
        "  ])\n",
        "  \n",
        "  # fetch and transform the images using torchvision transforms to create dataset\n",
        "  # from the image folder\n",
        "  ds = ImageFolder(config.imgs_folder, train_transform)\n",
        "  class_num = ds[-1][1] + 1 # total class is the index of last folder + 1\n",
        "  return ds, class_num\n",
        "\n",
        "# create train dataset\n",
        "train_ds, train_class_num = get_train_dataset(config)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj8afp7beqOY",
        "outputId": "6184e9b5-0453-4c35-c1c0-6835c0086f49"
      },
      "source": [
        "print(f'Train Dataset info {train_ds},\\ncontains {train_class_num} different identities!')\n",
        "print(f'Classes available in the dataset \\n{train_ds.classes},\\nhaving class ids {set(train_ds.targets)} respectively!')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Dataset info Dataset ImageFolder\n",
            "    Number of datapoints: 274\n",
            "    Root location: /content/gdrive/MyDrive/Kaggle Avengers face dataset/Marvels_face_dataset\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "               Resize(size=[112, 112], interpolation=bicubic)\n",
            "           ),\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids {0, 1, 2, 3, 4} respectively!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d26FsmHbHmrd"
      },
      "source": [
        "#### **Define Pytorch DataLoader**\n",
        "\n",
        "Define the train_loader function, where we can pass dataset mode(as 'vgg' or 'ms1m') through configuration dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAw9Q3NUfLaN"
      },
      "source": [
        "# define the train_loader function, where we can pass dataset mode(as 'vgg' or 'ms1m') through configuration dictionary\n",
        "def get_train_loader(ds, class_num, config):\n",
        "  if config.data_mode in ['ms1m','vgg']:\n",
        "    # create train_loader, by deafult shuffles the datapoints\n",
        "    train_loader = DataLoader(ds, batch_size=config.batch_size, shuffle = True, pin_memory = config.pin_memory,\n",
        "                              num_workers = config.num_workers)\n",
        "    return train_loader, train_class_num"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfnaI9XtQIji"
      },
      "source": [
        "**Defining metadata parameters to config**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5S0Vt9ffMhZ"
      },
      "source": [
        "# initializing data_mode as 'ms1m' dataset\n",
        "config.data_mode = 'ms1m'\n",
        "# initializing batch_size to 64\n",
        "config.batch_size = 64\n",
        "# pin_memory status is set to True, which enables to load samples of data to device(GPU), spped-up the training\n",
        "config.pin_memory = True\n",
        "# initializing the number of workers to 4\n",
        "config.num_workers = 4"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUZjUs5BRW8q"
      },
      "source": [
        "**Create the train dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WObWUDuQRSaX",
        "outputId": "c10af138-56b3-4410-a8b6-54119593e579"
      },
      "source": [
        "train_loader, _ = get_train_loader(train_ds, train_class_num, config)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzlghrVxUq3u"
      },
      "source": [
        "## **ArcFace Model Build**\n",
        "\n",
        "There are Backbone, Mobilefacenet models for generating face embedding. But, We are considering to use only Mobilefacenet, as it's a light-weight model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6hs96pOaccd"
      },
      "source": [
        "**Define Flatten Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4-X4Sbxaf8u"
      },
      "source": [
        "# flatten block\n",
        "class Flatten(Module):\n",
        "  def forward(self, input):\n",
        "    return input.view(input.size(0), -1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fi7MMtgIkG2"
      },
      "source": [
        "**Define L2_norm block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQx5QNTIN4c"
      },
      "source": [
        "def l2_norm(input, axis = 1):\n",
        "  norm = torch.norm(input, 2, axis, True)\n",
        "  output = torch.div(input, norm)\n",
        "  return output"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLRCOUpxX6wB"
      },
      "source": [
        "**Define a Convolution Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1id3S3CSpSF"
      },
      "source": [
        "# defining torch deafult sub-class api\n",
        "# PReLU - Parameterized ReLU used to handle the variations(parameterize activation @ x< 0) in lower level layers \n",
        "class Conv_block(Module):\n",
        "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
        "        super(Conv_block, self).__init__()\n",
        "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = BatchNorm2d(out_c)\n",
        "        self.prelu = PReLU(out_c)\n",
        "    \n",
        "    # forward prop\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcrBYfTY79e"
      },
      "source": [
        "**Define Linear Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGq9kN9YYyXO"
      },
      "source": [
        "class Linear_block(Module):\n",
        "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
        "        super(Linear_block, self).__init__()\n",
        "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = BatchNorm2d(out_c)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa74jnIgZyuM"
      },
      "source": [
        "**Define Depthwise Seperable Convolution Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7k3cgZaZC_-"
      },
      "source": [
        "class Depth_Wise(Module):\n",
        "     def __init__(self, in_c, out_c, residual = False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n",
        "        super(Depth_Wise, self).__init__()\n",
        "        self.conv = Conv_block(in_c, out_c=groups, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
        "        self.conv_dw = Conv_block(groups, groups, groups=groups, kernel=kernel, padding=padding, stride=stride)\n",
        "        self.project = Linear_block(groups, out_c, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
        "        self.residual = residual\n",
        "     def forward(self, x):\n",
        "        if self.residual:\n",
        "            short_cut = x\n",
        "        x = self.conv(x)\n",
        "        x = self.conv_dw(x)\n",
        "        x = self.project(x)\n",
        "        if self.residual:\n",
        "            output = short_cut + x\n",
        "        else:\n",
        "            output = x\n",
        "        return output"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8OKMNGZ7p9"
      },
      "source": [
        "**Define Residual Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNmIhnvBZxqS"
      },
      "source": [
        "class Residual(Module):\n",
        "    def __init__(self, c, num_block, groups, kernel=(3, 3), stride=(1, 1), padding=(1, 1)):\n",
        "        super(Residual, self).__init__()\n",
        "        modules = []\n",
        "        for _ in range(num_block):\n",
        "            modules.append(Depth_Wise(c, c, residual=True, kernel=kernel, padding=padding, stride=stride, groups=groups))\n",
        "        self.model = Sequential(*modules)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzu8yy5tb3Jw"
      },
      "source": [
        "**Define the embedding-size in the config**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLl1sgxwb8sf"
      },
      "source": [
        "config.embedding_size = 512"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G8j98wDaEqv"
      },
      "source": [
        "#### **Define Mobilefacenet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJxyMSbtZ-oS"
      },
      "source": [
        "class MobileFaceNet(Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(MobileFaceNet, self).__init__()\n",
        "        self.conv1 = Conv_block(3, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.conv2_dw = Conv_block(64, 64, kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
        "        self.conv_23 = Depth_Wise(64, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
        "        self.conv_3 = Residual(64, num_block=4, groups=128, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_34 = Depth_Wise(64, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
        "        self.conv_4 = Residual(128, num_block=6, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_45 = Depth_Wise(128, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
        "        self.conv_5 = Residual(128, num_block=2, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_6_sep = Conv_block(128, 512, kernel=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.conv_6_dw = Linear_block(512, 512, groups=512, kernel=(7,7), stride=(1, 1), padding=(0, 0))\n",
        "        self.conv_6_flatten = Flatten()\n",
        "        self.linear = Linear(512, embedding_size, bias=False)\n",
        "        self.bn = BatchNorm1d(embedding_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        out = self.conv2_dw(out)\n",
        "\n",
        "        out = self.conv_23(out)\n",
        "\n",
        "        out = self.conv_3(out)\n",
        "        \n",
        "        out = self.conv_34(out)\n",
        "\n",
        "        out = self.conv_4(out)\n",
        "\n",
        "        out = self.conv_45(out)\n",
        "\n",
        "        out = self.conv_5(out)\n",
        "\n",
        "        out = self.conv_6_sep(out)\n",
        "\n",
        "        out = self.conv_6_dw(out)\n",
        "\n",
        "        out = self.conv_6_flatten(out)\n",
        "\n",
        "        out = self.linear(out)\n",
        "\n",
        "        out = self.bn(out)\n",
        "        return l2_norm(out)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bUTjMzbbL86"
      },
      "source": [
        "**Initialize the Mobilefacenet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkCzWhbnaMVp"
      },
      "source": [
        "# call model object\n",
        "mobilefacenet_model = model.MobileFaceNet(embedding_size= config.embedding_size).to(config.device)\n",
        "\n",
        "#print(f'Model summary:\\n{mobilefacenet_model}')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9UbiBE8cNPZ"
      },
      "source": [
        "#### **Define Arcface Head**\n",
        "\n",
        "Implementation of **additive margin softmax** loss in https://arxiv.org/abs/1801.05599"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZE2bicla1Xj"
      },
      "source": [
        "class Arcface(Module):\n",
        "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599\n",
        "    # total class is set to deafult as the original dataset    \n",
        "    def __init__(self, embedding_size=512, classnum=51332,  s=64., m=0.5):\n",
        "        super(Arcface, self).__init__()\n",
        "        self.classnum = classnum\n",
        "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
        "        # initial kernel\n",
        "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
        "        self.m = m # the margin value, default is 0.5\n",
        "        self.s = s # scalar value default is 64, see normface https://arxiv.org/abs/1704.06369\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.mm = self.sin_m * m  # issue 1\n",
        "        self.threshold = math.cos(math.pi - m)\n",
        "    def forward(self, embbedings, label):\n",
        "        # weights norm\n",
        "        nB = len(embbedings)\n",
        "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
        "        # cos(theta+m)\n",
        "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
        "#         output = torch.mm(embbedings,kernel_norm)\n",
        "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
        "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
        "        sin_theta_2 = 1 - cos_theta_2\n",
        "        sin_theta = torch.sqrt(sin_theta_2)\n",
        "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
        "        # this condition controls the theta+m should in range [0, pi]\n",
        "        #      0<=theta+m<=pi\n",
        "        #     -m<=theta<=pi-m\n",
        "        cond_v = cos_theta - self.threshold\n",
        "        cond_mask = cond_v <= 0\n",
        "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
        "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
        "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
        "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
        "        output[idx_, label] = cos_theta_m[idx_, label]\n",
        "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
        "        return output"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyyovr1kgFV-"
      },
      "source": [
        "## **Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8q3l3NCm4ae"
      },
      "source": [
        "**Define to read bin of parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiqCLQb7mtcr"
      },
      "source": [
        "def seperate_bn_paras(modules):\n",
        "  # if modules is not object or instantiated\n",
        "  if not isinstance(modules, list):\n",
        "    modules = [*modules.modules()]\n",
        "  paras_only_bn = []\n",
        "  paras_wo_bn = []\n",
        "  for layer in modules:\n",
        "    if 'model' in str(layer.__class__):\n",
        "      continue\n",
        "    if 'container' in str(layer.__class__):\n",
        "      continue\n",
        "    else:\n",
        "      if 'batchnorm' in str(layer.__class__):\n",
        "        # takes bin of parameters\n",
        "        paras_only_bn.extend([*layer.parameters()])\n",
        "      else:\n",
        "        paras_wo_bn.extend([*layer.parameters()])\n",
        "  return paras_only_bn, paras_wo_bn\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJpqF3g9gc_4"
      },
      "source": [
        "**Initialize training and define training parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yikBZ5mgdJxd"
      },
      "source": [
        "class face_learner(object):\n",
        "  def __init__(self, config, model, train_loader, train_class_num, inference = False):\n",
        "    print(f'Configureation-\\n{config}')\n",
        "    # if we want to load MobileFcaenet model\n",
        "    if config.use_mobilefacenet:\n",
        "      # model already loaded to device\n",
        "      self.model = model\n",
        "      print('MobilefaceNet model generated!')\n",
        "    else:\n",
        "      print('Load the different model!')\n",
        "    \n",
        "    # defines the milestones where, the lr_scheduler will act\n",
        "    self.milestones = config.milestones\n",
        "    self.loader, self.class_num = train_loader, train_class_num\n",
        "\n",
        "    # helps to log summary of training using TensorboardX\n",
        "    #self.writer = SummaryWriter(config.log_path)\n",
        "    self.step = 0\n",
        "    self.head = Arcface(embedding_size=config.embedding_size, classnum=self.class_num).to(device)\n",
        "\n",
        "    print('Two model heads generated!')\n",
        "\n",
        "    paras_only_bn, paras_wo_bn = seperate_bn_paras(self.model)   \n",
        "    print(len(paras_only_bn))\n",
        "    print(len(paras_wo_bn))\n",
        "    # define optimizer for mobilefacenet\n",
        "    if config.use_mobilefacenet:\n",
        "      self.optimizer = optim.SGD([\n",
        "                                  {'params': paras_wo_bn[:-1], 'weight_decay': 4e-05},# weight decay for the params\n",
        "                                  {'params': [paras_wo_bn[-1]] + [self.head.kernel], 'weight_decay': 4e-04},\n",
        "                                  {'params': paras_only_bn}\n",
        "      ], lr = config.lr, momentum = config.momentum)\n",
        "    \n",
        "    else:\n",
        "      self.optimizer = optim.SGD([\n",
        "                                  {'params': paras_wo_bn + [self.head.kernel], 'weight_decay': 5e-04},\n",
        "                                  {'params': paras_only_bn}\n",
        "      ], lr = config.lr, momentum = config.momentum)\n",
        "  \n",
        "    print(self.optimizer)\n",
        "    \n",
        "    print('Optimizers generated')\n",
        "    # log loss to every (len of loader//100) step\n",
        "    self.board_loss_every = len(self.loader)//100\n",
        "    # evaluate every (len of loader//10) step\n",
        "    self.evaluate_every = len(self.loader)//10\n",
        "    # save after (len(loader)//5) step\n",
        "    self.save_every = len(self.loader)//5\n",
        "    \n",
        "  # lr scheduler\n",
        "  def schedule_lr(self):\n",
        "    for params in self.optimizer.param_groups:\n",
        "      params['lr']/=10\n",
        "    print(self.optimizer)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioODXmgHxG3n"
      },
      "source": [
        "**Configure metadata for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6teOQS_mxGer"
      },
      "source": [
        "# define work_space \n",
        "config.work_path = Path('work_space/')\n",
        "\n",
        "# create work_space path, if not existed\n",
        "if not os.path.isdir(config.work_path):\n",
        "  os.mkdir(config.work_path)\n",
        "\n",
        "# configure logpath\n",
        "config.log_path = config.work_path/'log'\n",
        "\n",
        "# create log path, if not existed\n",
        "#if not os.path.isdir(config.work_path/'log'):\n",
        "#  os.mkdir(config.work_path/'log')\n",
        "\n",
        "# configure mobilefacenet status\n",
        "config.use_mobilefacenet = True\n",
        "\n",
        "# configure milestones\n",
        "config.milestones = [12,15,18]\n",
        "\n",
        "# configure momentum\n",
        "config.momentum = 0.9\n",
        "\n",
        "# configure learning rate\n",
        "config.lr = 1e-03\n",
        "\n",
        "# loss fn\n",
        "config.ce_loss = CrossEntropyLoss()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbgVDQCwz3n"
      },
      "source": [
        "#### **Define Model Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9NZKzkHomwF"
      },
      "source": [
        "def train(config, epochs):\n",
        "  learner = face_learner(config, mobilefacenet_model, train_loader, train_class_num)\n",
        "  learner.model.train()\n",
        "  running_loss = 0\n",
        "  for e in range(epochs):\n",
        "    print('epoch {} started'.format(e))\n",
        "    # at each milestone learning rate is changes according to the scheduler\n",
        "    if e == learner.milestones[0]:\n",
        "        learner.schedule_lr()\n",
        "    if e == learner.milestones[1]:\n",
        "        learner.schedule_lr()      \n",
        "    if e == learner.milestones[2]:\n",
        "        learner.schedule_lr()                                 \n",
        "    \n",
        "    for imgs, labels in tqdm(iter(learner.loader)):\n",
        "        imgs = imgs.to(config.device)\n",
        "        labels = labels.to(config.device)\n",
        "        learner.optimizer.zero_grad()\n",
        "        embeddings = learner.model(imgs)\n",
        "        thetas = learner.head(embeddings, labels)\n",
        "        loss = config.ce_loss(thetas, labels)\n",
        "        loss.backward()\n",
        "        running_loss += loss.item()\n",
        "        learner.optimizer.step()\n",
        "        \n",
        "        if learner.step % learner.board_loss_every == 0 and learner.step != 0:\n",
        "            loss_board = running_loss / learner.board_loss_every\n",
        "            learner.writer.add_scalar('train_loss', loss_board, self.step)\n",
        "            running_loss = 0.\n",
        "        \n",
        "        '''\n",
        "        if self.step % self.evaluate_every == 0 and self.step != 0:\n",
        "            accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.agedb_30, self.agedb_30_issame)\n",
        "            self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\n",
        "            accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.lfw, self.lfw_issame)\n",
        "            self.board_val('lfw', accuracy, best_threshold, roc_curve_tensor)\n",
        "            accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.cfp_fp, self.cfp_fp_issame)\n",
        "            self.board_val('cfp_fp', accuracy, best_threshold, roc_curve_tensor)\n",
        "            self.model.train()\n",
        "        if self.step % self.save_every == 0 and self.step != 0:\n",
        "            self.save_state(conf, accuracy)\n",
        "        '''    \n",
        "        learner.step += 1\n",
        "        "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC08M0c-zlNQ",
        "outputId": "97616407-2904-4e79-b5c9-36cd5fdddb55"
      },
      "source": [
        "train(config, epochs = 20)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Configureation-\n",
            "{'device': device(type='cuda', index=0), 'imgs_folder': '/content/gdrive/MyDrive/Kaggle Avengers face dataset/Marvels_face_dataset', 'data_mode': 'ms1m', 'batch_size': 64, 'pin_memory': True, 'num_workers': 4, 'embedding_size': 512, 'work_path': PosixPath('work_space'), 'log_path': PosixPath('work_space/log'), 'use_mobilefacenet': True, 'milestones': [12, 15, 18], 'momentum': 0.9, 'lr': 0.001, 'ce_loss': CrossEntropyLoss(), 'input_size': [112, 112]}\n",
            "MobilefaceNet model generated!\n",
            "Two model heads generated!\n",
            "100\n",
            "83\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Optimizers generated\n",
            "epoch 0 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.18s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.57s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.14s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.96s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.42s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.03s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.00s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.44s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.05s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.82s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:01<00:03,  1.32s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.03it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.72s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.31s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.05it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.79s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.34s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.02it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.65s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:01<00:03,  1.20s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.08it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  2.00s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.44s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.05s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.94s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.40s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.02s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.03s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.47s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.07s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.85s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.39s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.01s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.61s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.07it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.73s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.30s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.05it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 13 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.81s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:01<00:03,  1.32s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.04it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.96s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.42s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.04s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 15 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.98s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.43s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.04s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 16 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.61s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.26s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.08it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 17 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.02s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.46s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.06s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 18 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.10s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.51s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.09s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 19 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.99s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.44s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:02,  1.05s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}