{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_pipeline_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZYNFpnLdfCP8CGwqhQN2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayan0506/Face-Recognition-pipeline-using-SOTA-ArcFace/blob/main/Test_pipeline_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEpYLpQ5MBjN"
      },
      "source": [
        "## **Mount Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8KztPV1nNCE",
        "outputId": "b3db4511-1a31-410c-838e-899d18d78087"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/grive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/grive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n3Rb7vKMG3J"
      },
      "source": [
        "## **Execute Train Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awQXICM4Er_N",
        "outputId": "c273533d-d3e5-4f64-b50b-32d910f8555d"
      },
      "source": [
        "!python train.py -dataset /content/grive/MyDrive/Kaggle_Avengers_face_dataset/Marvels_face_dataset -model ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n",
            "Device info\n",
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n",
            "Best validated model will be saved in \"saved_model\" folder!\n",
            "\n",
            "[INFO] Loading images ...\n",
            "[INFO] Processing chris_evans\n",
            "50\n",
            "[INFO] Processing chris_hemsworth\n",
            "53\n",
            "[INFO] Processing mark_ruffalo\n",
            "66\n",
            "[INFO] Processing robert_downey_jr\n",
            "51\n",
            "[INFO] Processing scarlett_johansson\n",
            "54\n",
            "Data distribution of different identities\n",
            "  chris_evans  ... scarlett_johansson\n",
            "0          50  ...                 54\n",
            "\n",
            "[1 rows x 5 columns]\n",
            "Image dataframe\n",
            "                        Image               Label\n",
            "0           chris_evans34.png         chris_evans\n",
            "1           chris_evans32.png         chris_evans\n",
            "2            chris_evans6.png         chris_evans\n",
            "3           chris_evans47.png         chris_evans\n",
            "4           chris_evans13.png         chris_evans\n",
            "..                        ...                 ...\n",
            "269  scarlett_johansson54.png  scarlett_johansson\n",
            "270  scarlett_johansson52.png  scarlett_johansson\n",
            "271   scarlett_johansson9.png  scarlett_johansson\n",
            "272  scarlett_johansson53.png  scarlett_johansson\n",
            "273   scarlett_johansson5.png  scarlett_johansson\n",
            "\n",
            "[274 rows x 2 columns]\n",
            "Stratified split distribution-\n",
            "mark_ruffalo          59\n",
            "chris_hemsworth       48\n",
            "scarlett_johansson    48\n",
            "robert_downey_jr      46\n",
            "chris_evans           45\n",
            "Name: Label, dtype: int64\n",
            "mark_ruffalo          4\n",
            "scarlett_johansson    3\n",
            "chris_evans           3\n",
            "robert_downey_jr      2\n",
            "chris_hemsworth       2\n",
            "Name: Label, dtype: int64\n",
            "robert_downey_jr      3\n",
            "scarlett_johansson    3\n",
            "chris_hemsworth       3\n",
            "mark_ruffalo          3\n",
            "chris_evans           2\n",
            "Name: Label, dtype: int64\n",
            "Train, Valid, Test dataframes are stored in csv to csv_data_files\n",
            "\n",
            "Train Dataset info <FaceDataset.FaceDataset object at 0x7fddba33d410>,\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids [0, 1, 2, 3, 4] respectively!\n",
            "Length of the dataset 246\n",
            "\n",
            "Validation Dataset info <FaceDataset.FaceDataset object at 0x7fddba33d850>,\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids [0, 1, 2, 3, 4] respectively!\n",
            "Length of the dataset 14\n",
            "\n",
            "Test Dataset info <FaceDataset.FaceDataset object at 0x7fddba35fb50>,\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids [0, 1, 2, 3, 4] respectively!\n",
            "Length of the dataset 14\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Train, valid, test dataloader have created!\n",
            "\n",
            "MobileFcaenet Model create\n",
            "Model summary\n",
            "MobileFaceNet(\n",
            "  (conv1): Conv_block(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (prelu): PReLU(num_parameters=64)\n",
            "  )\n",
            "  (conv2_dw): Conv_block(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (prelu): PReLU(num_parameters=64)\n",
            "  )\n",
            "  (conv_23): Depth_Wise(\n",
            "    (conv): Conv_block(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=128)\n",
            "    )\n",
            "    (conv_dw): Conv_block(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=128)\n",
            "    )\n",
            "    (project): Linear_block(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (conv_3): Residual(\n",
            "    (model): Sequential(\n",
            "      (0): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=128)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_34): Depth_Wise(\n",
            "    (conv): Conv_block(\n",
            "      (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=256)\n",
            "    )\n",
            "    (conv_dw): Conv_block(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=256)\n",
            "    )\n",
            "    (project): Linear_block(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (conv_4): Residual(\n",
            "    (model): Sequential(\n",
            "      (0): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_45): Depth_Wise(\n",
            "    (conv): Conv_block(\n",
            "      (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=512)\n",
            "    )\n",
            "    (conv_dw): Conv_block(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=512)\n",
            "    )\n",
            "    (project): Linear_block(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (conv_5): Residual(\n",
            "    (model): Sequential(\n",
            "      (0): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Depth_Wise(\n",
            "        (conv): Conv_block(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (conv_dw): Conv_block(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (prelu): PReLU(num_parameters=256)\n",
            "        )\n",
            "        (project): Linear_block(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_6_sep): Conv_block(\n",
            "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (prelu): PReLU(num_parameters=512)\n",
            "  )\n",
            "  (conv_6_dw): Linear_block(\n",
            "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
            "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_6_flatten): Flatten()\n",
            "  (linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "Configureation-\n",
            "{'device': device(type='cuda', index=0), 'imgs_folder': '/content/grive/MyDrive/Kaggle_Avengers_face_dataset/Marvels_face_dataset', 'csv_path': 'csv_data_files', 'identity_list': ['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'], 'input_size': [112, 112], 'transform': Compose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "    Resize(size=[112, 112], interpolation=bicubic)\n",
            "), 'data_mode': 'ms1m', 'batch_size': 64, 'pin_memory': True, 'num_workers': 3, 'embedding_size': 512, 'use_mobilefacenet': True, 'milestones': [12, 15, 18], 'momentum': 0.9, 'lr': 0.001, 'ce_loss': CrossEntropyLoss(), 'pretrained_save_path': '.', 'save_path': 'saved_model', 'split_ratio': [0.9, 0.05, 0.05], 'train_df':                         Image               Label\n",
            "46          chris_evans24.png         chris_evans\n",
            "242   scarlett_johansson4.png  scarlett_johansson\n",
            "224  scarlett_johansson23.png  scarlett_johansson\n",
            "188     robert_downey_jr5.png    robert_downey_jr\n",
            "260  scarlett_johansson24.png  scarlett_johansson\n",
            "..                        ...                 ...\n",
            "49           chris_evans4.png         chris_evans\n",
            "184    robert_downey_jr37.png    robert_downey_jr\n",
            "17          chris_evans14.png         chris_evans\n",
            "218     robert_downey_jr7.png    robert_downey_jr\n",
            "147        mark_ruffalo47.png        mark_ruffalo\n",
            "\n",
            "[246 rows x 2 columns], 'valid_df':                         Image               Label\n",
            "5           chris_evans48.png         chris_evans\n",
            "249  scarlett_johansson44.png  scarlett_johansson\n",
            "101      chris_hemsworth6.png     chris_hemsworth\n",
            "32          chris_evans17.png         chris_evans\n",
            "256  scarlett_johansson28.png  scarlett_johansson\n",
            "231   scarlett_johansson1.png  scarlett_johansson\n",
            "205     robert_downey_jr2.png    robert_downey_jr\n",
            "120        mark_ruffalo27.png        mark_ruffalo\n",
            "187    robert_downey_jr23.png    robert_downey_jr\n",
            "146        mark_ruffalo53.png        mark_ruffalo\n",
            "67      chris_hemsworth19.png     chris_hemsworth\n",
            "160        mark_ruffalo51.png        mark_ruffalo\n",
            "149        mark_ruffalo54.png        mark_ruffalo\n",
            "1           chris_evans32.png         chris_evans, 'test_df':                         Image               Label\n",
            "232  scarlett_johansson36.png  scarlett_johansson\n",
            "244  scarlett_johansson35.png  scarlett_johansson\n",
            "174    robert_downey_jr12.png    robert_downey_jr\n",
            "141        mark_ruffalo42.png        mark_ruffalo\n",
            "140         mark_ruffalo2.png        mark_ruffalo\n",
            "143         mark_ruffalo7.png        mark_ruffalo\n",
            "22           chris_evans7.png         chris_evans\n",
            "52      chris_hemsworth10.png     chris_hemsworth\n",
            "211    robert_downey_jr17.png    robert_downey_jr\n",
            "3           chris_evans47.png         chris_evans\n",
            "60      chris_hemsworth25.png     chris_hemsworth\n",
            "175    robert_downey_jr40.png    robert_downey_jr\n",
            "233  scarlett_johansson10.png  scarlett_johansson\n",
            "102     chris_hemsworth39.png     chris_hemsworth}\n",
            "MobilefaceNet model generated!\n",
            "Two model heads generated!\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Optimizers generated\n",
            "Mobilenet pre-trained loaded successfully!\n",
            "epoch 0 started\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 1 is  32.5552864074707\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.42it/s]\n",
            "Validation Loss of step 1 is 31.64478874206543\n",
            " 25% 1/4 [00:02<00:06,  2.17s/it]Train Loss of step 2 is  32.11274337768555\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.35it/s]\n",
            "Validation Loss of step 2 is 30.002140045166016\n",
            "Saving model at epoch 0, step 2\n",
            " 50% 2/4 [00:02<00:03,  1.69s/it]Train Loss of step 3 is  30.421777725219727\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 3 is 28.182968139648438\n",
            "Saving model at epoch 0, step 3\n",
            " 75% 3/4 [00:03<00:01,  1.35s/it]Train Loss of step 4 is  27.966835021972656\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.27it/s]\n",
            "Validation Loss of step 4 is 25.783639907836914\n",
            "Saving model at epoch 0, step 4\n",
            "100% 4/4 [00:03<00:00,  1.02it/s]\n",
            "epoch 1 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 5 is  25.108835220336914\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.02it/s]\n",
            "Validation Loss of step 5 is 23.226715087890625\n",
            "Saving model at epoch 1, step 5\n",
            " 25% 1/4 [00:02<00:06,  2.14s/it]Train Loss of step 6 is  21.698875427246094\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 6 is 20.20256233215332\n",
            "Saving model at epoch 1, step 6\n",
            " 50% 2/4 [00:02<00:03,  1.66s/it]Train Loss of step 7 is  17.78818130493164\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.22it/s]\n",
            "Validation Loss of step 7 is 16.76076889038086\n",
            "Saving model at epoch 1, step 7\n",
            " 75% 3/4 [00:03<00:01,  1.33s/it]Train Loss of step 8 is  15.41328239440918\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "Validation Loss of step 8 is 13.435147285461426\n",
            "Saving model at epoch 1, step 8\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 2 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 9 is  10.84256649017334\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.47it/s]\n",
            "Validation Loss of step 9 is 11.414520263671875\n",
            "Saving model at epoch 2, step 9\n",
            " 25% 1/4 [00:02<00:06,  2.23s/it]Train Loss of step 10 is  9.819183349609375\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.28it/s]\n",
            "Validation Loss of step 10 is 8.62656021118164\n",
            "Saving model at epoch 2, step 10\n",
            " 50% 2/4 [00:02<00:03,  1.74s/it]Train Loss of step 11 is  5.989723205566406\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "Validation Loss of step 11 is 6.757330894470215\n",
            "Saving model at epoch 2, step 11\n",
            " 75% 3/4 [00:03<00:01,  1.39s/it]Train Loss of step 12 is  2.432849645614624\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 12 is 5.792647838592529\n",
            "Saving model at epoch 2, step 12\n",
            "100% 4/4 [00:04<00:00,  1.00s/it]\n",
            "epoch 3 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 13 is  3.160587787628174\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "Validation Loss of step 13 is 4.26300573348999\n",
            "Saving model at epoch 3, step 13\n",
            " 25% 1/4 [00:02<00:06,  2.19s/it]Train Loss of step 14 is  2.460508346557617\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.32it/s]\n",
            "Validation Loss of step 14 is 4.338381767272949\n",
            " 50% 2/4 [00:02<00:03,  1.69s/it]Train Loss of step 15 is  0.8252443671226501\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.30it/s]\n",
            "Validation Loss of step 15 is 2.84161114692688\n",
            "Saving model at epoch 3, step 15\n",
            " 75% 3/4 [00:03<00:01,  1.35s/it]Train Loss of step 16 is  2.071218252182007\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.24it/s]\n",
            "Validation Loss of step 16 is 3.0634541511535645\n",
            "100% 4/4 [00:03<00:00,  1.04it/s]\n",
            "epoch 4 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 17 is  0.8612126708030701\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.68it/s]\n",
            "Validation Loss of step 17 is 2.919238567352295\n",
            " 25% 1/4 [00:02<00:06,  2.13s/it]Train Loss of step 18 is  0.5507130026817322\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.35it/s]\n",
            "Validation Loss of step 18 is 2.1023499965667725\n",
            "Saving model at epoch 4, step 18\n",
            " 50% 2/4 [00:02<00:03,  1.67s/it]Train Loss of step 19 is  0.6379225254058838\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.41it/s]\n",
            "Validation Loss of step 19 is 2.0581843852996826\n",
            "Saving model at epoch 4, step 19\n",
            " 75% 3/4 [00:03<00:01,  1.33s/it]Train Loss of step 20 is  0.34615328907966614\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.86it/s]\n",
            "Validation Loss of step 20 is 1.8136539459228516\n",
            "Saving model at epoch 4, step 20\n",
            "100% 4/4 [00:03<00:00,  1.01it/s]\n",
            "epoch 5 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 21 is  0.10552408546209335\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.41it/s]\n",
            "Validation Loss of step 21 is 1.7241297960281372\n",
            "Saving model at epoch 5, step 21\n",
            " 25% 1/4 [00:02<00:06,  2.11s/it]Train Loss of step 22 is  0.240126371383667\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "Validation Loss of step 22 is 1.3601449728012085\n",
            "Saving model at epoch 5, step 22\n",
            " 50% 2/4 [00:02<00:03,  1.65s/it]Train Loss of step 23 is  0.08290497958660126\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 23 is 1.64443039894104\n",
            " 75% 3/4 [00:03<00:01,  1.31s/it]Train Loss of step 24 is  6.700029189232737e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.40it/s]\n",
            "Validation Loss of step 24 is 1.5744744539260864\n",
            "100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "epoch 6 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 25 is  0.27272576093673706\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "Validation Loss of step 25 is 0.958035945892334\n",
            "Saving model at epoch 6, step 25\n",
            " 25% 1/4 [00:02<00:06,  2.18s/it]Train Loss of step 26 is  4.5842996769351885e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.30it/s]\n",
            "Validation Loss of step 26 is 1.3898388147354126\n",
            " 50% 2/4 [00:02<00:03,  1.69s/it]Train Loss of step 27 is  2.2165437485455186e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.36it/s]\n",
            "Validation Loss of step 27 is 1.5639851093292236\n",
            " 75% 3/4 [00:03<00:01,  1.34s/it]Train Loss of step 28 is  0.0019824078772217035\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.34it/s]\n",
            "Validation Loss of step 28 is 1.4179373979568481\n",
            "100% 4/4 [00:03<00:00,  1.04it/s]\n",
            "epoch 7 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 29 is  0.010789362713694572\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.12it/s]\n",
            "Validation Loss of step 29 is 1.5624401569366455\n",
            " 25% 1/4 [00:02<00:06,  2.14s/it]Train Loss of step 30 is  0.00022349198115989566\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.36it/s]\n",
            "Validation Loss of step 30 is 1.498653531074524\n",
            " 50% 2/4 [00:02<00:03,  1.65s/it]Train Loss of step 31 is  3.040414048882667e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.09it/s]\n",
            "Validation Loss of step 31 is 1.0909079313278198\n",
            " 75% 3/4 [00:03<00:01,  1.32s/it]Train Loss of step 32 is  0.0036195307038724422\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.36it/s]\n",
            "Validation Loss of step 32 is 1.4023401737213135\n",
            "100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "epoch 8 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 33 is  0.001177560305222869\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "Validation Loss of step 33 is 0.8332997560501099\n",
            "Saving model at epoch 8, step 33\n",
            " 25% 1/4 [00:02<00:06,  2.14s/it]Train Loss of step 34 is  0.13516706228256226\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "Validation Loss of step 34 is 1.0569157600402832\n",
            " 50% 2/4 [00:02<00:03,  1.66s/it]Train Loss of step 35 is  8.089748735073954e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.31it/s]\n",
            "Validation Loss of step 35 is 1.4087693691253662\n",
            " 75% 3/4 [00:03<00:01,  1.31s/it]Train Loss of step 36 is  0.05672459304332733\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "Validation Loss of step 36 is 0.8241996765136719\n",
            "Saving model at epoch 8, step 36\n",
            "100% 4/4 [00:03<00:00,  1.05it/s]\n",
            "epoch 9 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 37 is  0.06067377328872681\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "Validation Loss of step 37 is 1.2883261442184448\n",
            " 25% 1/4 [00:02<00:06,  2.04s/it]Train Loss of step 38 is  0.3353116810321808\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.23it/s]\n",
            "Validation Loss of step 38 is 1.5613040924072266\n",
            " 50% 2/4 [00:02<00:03,  1.59s/it]Train Loss of step 39 is  6.699551158817485e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.28it/s]\n",
            "Validation Loss of step 39 is 1.1394009590148926\n",
            " 75% 3/4 [00:03<00:01,  1.27s/it]Train Loss of step 40 is  0.05938832461833954\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.22it/s]\n",
            "Validation Loss of step 40 is 1.354835867881775\n",
            "100% 4/4 [00:03<00:00,  1.08it/s]\n",
            "epoch 10 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 41 is  3.551708232407691e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.39it/s]\n",
            "Validation Loss of step 41 is 0.795987069606781\n",
            "Saving model at epoch 10, step 41\n",
            " 25% 1/4 [00:02<00:06,  2.16s/it]Train Loss of step 42 is  4.3771967739303363e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.38it/s]\n",
            "Validation Loss of step 42 is 0.7206783294677734\n",
            "Saving model at epoch 10, step 42\n",
            " 50% 2/4 [00:02<00:03,  1.69s/it]Train Loss of step 43 is  3.5984880923933815e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.42it/s]\n",
            "Validation Loss of step 43 is 1.111876368522644\n",
            " 75% 3/4 [00:03<00:01,  1.34s/it]Train Loss of step 44 is  7.660238452444901e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.41it/s]\n",
            "Validation Loss of step 44 is 0.9637032151222229\n",
            "100% 4/4 [00:03<00:00,  1.04it/s]\n",
            "epoch 11 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 45 is  0.0021049482747912407\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "Validation Loss of step 45 is 1.052172064781189\n",
            " 25% 1/4 [00:02<00:06,  2.13s/it]Train Loss of step 46 is  9.69375905697234e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.28it/s]\n",
            "Validation Loss of step 46 is 1.0079811811447144\n",
            " 50% 2/4 [00:02<00:03,  1.64s/it]Train Loss of step 47 is  4.138341409998247e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "Validation Loss of step 47 is 0.6500795483589172\n",
            "Saving model at epoch 11, step 47\n",
            " 75% 3/4 [00:03<00:01,  1.32s/it]Train Loss of step 48 is  1.024288735607115e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.36it/s]\n",
            "Validation Loss of step 48 is 0.6597443222999573\n",
            "100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "epoch 12 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 49 is  0.03471765294671059\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.65it/s]\n",
            "Validation Loss of step 49 is 1.0493165254592896\n",
            " 25% 1/4 [00:02<00:06,  2.18s/it]Train Loss of step 50 is  1.0095320703840116e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "Validation Loss of step 50 is 1.0072730779647827\n",
            " 50% 2/4 [00:02<00:03,  1.68s/it]Train Loss of step 51 is  8.568162002120516e-08\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "Validation Loss of step 51 is 1.30679190158844\n",
            " 75% 3/4 [00:03<00:01,  1.34s/it]Train Loss of step 52 is  9.764394235389773e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 52 is 0.6285547018051147\n",
            "Saving model at epoch 12, step 52\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 13 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 53 is  0.025121308863162994\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.49it/s]\n",
            "Validation Loss of step 53 is 0.7467080354690552\n",
            " 25% 1/4 [00:02<00:06,  2.24s/it]Train Loss of step 54 is  1.517959844932193e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 54 is 0.7933188080787659\n",
            " 50% 2/4 [00:02<00:03,  1.73s/it]Train Loss of step 55 is  0.0033178541343659163\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.27it/s]\n",
            "Validation Loss of step 55 is 0.6344751119613647\n",
            " 75% 3/4 [00:03<00:01,  1.36s/it]Train Loss of step 56 is  4.172286196535424e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.34it/s]\n",
            "Validation Loss of step 56 is 0.7028012275695801\n",
            "100% 4/4 [00:03<00:00,  1.04it/s]\n",
            "epoch 14 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 57 is  7.714737876085564e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "Validation Loss of step 57 is 0.7950507998466492\n",
            " 25% 1/4 [00:02<00:06,  2.16s/it]Train Loss of step 58 is  2.3164042431744747e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "Validation Loss of step 58 is 0.785958468914032\n",
            " 50% 2/4 [00:02<00:03,  1.67s/it]Train Loss of step 59 is  8.303861250169575e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "Validation Loss of step 59 is 0.7982544302940369\n",
            " 75% 3/4 [00:03<00:01,  1.33s/it]Train Loss of step 60 is  1.1700153379479161e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.27it/s]\n",
            "Validation Loss of step 60 is 0.5250746011734009\n",
            "Saving model at epoch 14, step 60\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 15 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 61 is  2.6785724912770092e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "Validation Loss of step 61 is 1.1770217418670654\n",
            " 25% 1/4 [00:02<00:06,  2.21s/it]Train Loss of step 62 is  3.0489295568258967e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "Validation Loss of step 62 is 1.3176428079605103\n",
            " 50% 2/4 [00:02<00:03,  1.71s/it]Train Loss of step 63 is  2.158550705644302e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.24it/s]\n",
            "Validation Loss of step 63 is 1.1406387090682983\n",
            " 75% 3/4 [00:03<00:01,  1.35s/it]Train Loss of step 64 is  0.00938554760068655\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.11it/s]\n",
            "Validation Loss of step 64 is 0.7187789678573608\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 16 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 65 is  2.9243321364447183e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.52it/s]\n",
            "Validation Loss of step 65 is 1.1796519756317139\n",
            " 25% 1/4 [00:02<00:06,  2.23s/it]Train Loss of step 66 is  0.0698995590209961\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "Validation Loss of step 66 is 0.7155694961547852\n",
            " 50% 2/4 [00:02<00:03,  1.72s/it]Train Loss of step 67 is  2.9802311729554276e-08\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.21it/s]\n",
            "Validation Loss of step 67 is 0.67987459897995\n",
            " 75% 3/4 [00:03<00:01,  1.36s/it]Train Loss of step 68 is  0.00047489837743341923\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.07it/s]\n",
            "Validation Loss of step 68 is 1.0927780866622925\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 17 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 69 is  0.06648063659667969\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.27it/s]\n",
            "Validation Loss of step 69 is 0.9822549223899841\n",
            " 25% 1/4 [00:02<00:06,  2.22s/it]Train Loss of step 70 is  3.773810021812096e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.14it/s]\n",
            "Validation Loss of step 70 is 0.5578874349594116\n",
            " 50% 2/4 [00:02<00:03,  1.72s/it]Train Loss of step 71 is  7.84827716415748e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "Validation Loss of step 71 is 1.0002009868621826\n",
            " 75% 3/4 [00:03<00:01,  1.37s/it]Train Loss of step 72 is  1.1446705684647895e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.09it/s]\n",
            "Validation Loss of step 72 is 0.9079006910324097\n",
            "100% 4/4 [00:03<00:00,  1.02it/s]\n",
            "epoch 18 started\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 4e-05\n",
            "\n",
            "Parameter Group 1\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0004\n",
            "\n",
            "Parameter Group 2\n",
            "    dampening: 0\n",
            "    lr: 1.0000000000000002e-06\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 73 is  1.223281924467301e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.97it/s]\n",
            "Validation Loss of step 73 is 1.013351321220398\n",
            " 25% 1/4 [00:02<00:06,  2.18s/it]Train Loss of step 74 is  6.970396043470828e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.25it/s]\n",
            "Validation Loss of step 74 is 0.6531780958175659\n",
            " 50% 2/4 [00:02<00:03,  1.69s/it]Train Loss of step 75 is  2.0302786651882343e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.35it/s]\n",
            "Validation Loss of step 75 is 0.46628400683403015\n",
            "Saving model at epoch 18, step 75\n",
            " 75% 3/4 [00:03<00:01,  1.35s/it]Train Loss of step 76 is  7.969284752107342e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.08it/s]\n",
            "Validation Loss of step 76 is 1.1479870080947876\n",
            "100% 4/4 [00:03<00:00,  1.03it/s]\n",
            "epoch 19 started\n",
            "  0% 0/4 [00:00<?, ?it/s]Train Loss of step 77 is  2.1688359993277118e-05\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "Validation Loss of step 77 is 0.8226794004440308\n",
            " 25% 1/4 [00:02<00:06,  2.09s/it]Train Loss of step 78 is  5.662406579176604e-07\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.35it/s]\n",
            "Validation Loss of step 78 is 0.7832812070846558\n",
            " 50% 2/4 [00:02<00:03,  1.63s/it]Train Loss of step 79 is  2.5423428269277792e-06\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.32it/s]\n",
            "Validation Loss of step 79 is 1.0850332975387573\n",
            " 75% 3/4 [00:03<00:01,  1.30s/it]Train Loss of step 80 is  5.0774296767031046e-08\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.12it/s]\n",
            "Validation Loss of step 80 is 1.0778682231903076\n",
            "100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "\n",
            "Min validation loss - 0.46628400683403015\n",
            "\n",
            "Best model based on validation data result - ('saved_model/model_step_75_loss_0.46628400683403015.path', 'saved_model/head_step_75_loss_0.46628400683403015.path', 'saved_model/optimizer_step_75_loss_0.46628400683403015.path')\n",
            "Configuration is stored in 'config.yml!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK8uf3YhMcDJ"
      },
      "source": [
        "## **Execute Test pipeline**\n",
        "\n",
        "Note: python test.py bash implementation is not shown in the demo, but that code is working properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9XcbmZ7GsFF"
      },
      "source": [
        "# import test module\n",
        "import test"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikj-x_65Qyxe",
        "outputId": "26a5c28a-e24a-41d7-8a00-cc64ae28c8ee"
      },
      "source": [
        "# create test instance\n",
        "t= test.test_pipeline('/content/grive/MyDrive/Kaggle_Avengers_face_dataset','.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n",
            "Device info\n",
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3sh5qF8REWh",
        "outputId": "2553e8ca-31a3-4b9b-ff13-2f5daf579acb"
      },
      "source": [
        "# run test pipeline\n",
        "t.run_pipeline()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Dataset info <FaceDataset.FaceDataset object at 0x7f27b938e450>,\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids [0, 1, 2, 3, 4] respectively!\n",
            "Length of the dataset 14\n",
            "\n",
            "Test Dataset info <FaceDataset.FaceDataset object at 0x7f27ca8e1310>,\n",
            "contains 5 different identities!\n",
            "Classes available in the dataset \n",
            "['chris_evans', 'chris_hemsworth', 'mark_ruffalo', 'robert_downey_jr', 'scarlett_johansson'],\n",
            "having class ids [0, 1, 2, 3, 4] respectively!\n",
            "Length of the dataset 14\n",
            "\n",
            "Train, valid, test dataloader have created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MobilefaceNet model loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V67-oZjEMzOj"
      },
      "source": [
        "## **Build Requirements**\n",
        "\n",
        "Create requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py29sahtRP_r"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data pipeline\n",
        "# helps to create dict where, use keys as atribute\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "from torchvision import transforms as trans\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image, ImageFile, ImageDraw\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ensures loading truncated images \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# model build\n",
        "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from collections import namedtuple\n",
        "import math\n",
        "import pdb\n",
        "\n",
        "# model training\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS4qiRdjOdVe"
      },
      "source": [
        "**Obtaining versions of different modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55UUSrRzL1t2",
        "outputId": "022df726-7e83-4685-c3cc-1d3ad300e42c"
      },
      "source": [
        "# numpy\n",
        "!pip freeze | grep numpy\n",
        "# os\n",
        "!pip freeze | grep os\n",
        "# pandas\n",
        "!pip freeze | grep pandas\n",
        "# matplotlib\n",
        "!pip freeze | grep matplotlib\n",
        "# pytorch\n",
        "!pip freeze | grep torch"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy==1.19.5\n",
            "ecos==2.0.7.post1\n",
            "googleapis-common-protos==1.53.0\n",
            "ideep4py==2.0.0.post3\n",
            "librosa==0.8.0\n",
            "osqp==0.6.2.post0\n",
            "qdldl==0.1.5.post0\n",
            "scikit-learn==0.22.2.post1\n",
            "SoundFile==0.10.3.post1\n",
            "xgboost==0.90\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "sklearn-pandas==1.8.0\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PxOICZyOmU-",
        "outputId": "99215d46-f829-4f1b-cf7e-9ca96db8d377"
      },
      "source": [
        "# tqdm\n",
        "!pip freeze | tqdm"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]absl-py==0.12.0\n",
            "1it [00:00,  1.95it/s]alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.266\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.30.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.0.1\n",
            "importlib-resources==5.1.3\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.4\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.15\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.0\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n",
            "383it [00:00, 677.89it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J31o1O3AXzY_"
      },
      "source": [
        "## **Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtGR5ejOXifV",
        "outputId": "7427f472-56d7-4b2b-876e-969106cef403"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: ecos==2.0.7.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.0.7.post1)\n",
            "Requirement already satisfied: googleapis-common-protos==1.53.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.53.0)\n",
            "Requirement already satisfied: ideep4py==2.0.0.post3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.0.0.post3)\n",
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: osqp==0.6.2.post0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.6.2.post0)\n",
            "Requirement already satisfied: qdldl==0.1.5.post0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.1.5.post0)\n",
            "Requirement already satisfied: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: SoundFile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.10.3.post1)\n",
            "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: pandas-datareader==0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: pandas-gbq==0.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.3)\n",
            "Requirement already satisfied: pandas-profiling==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: sklearn-pandas==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (3.2.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.1.2)\n",
            "Requirement already satisfied: matplotlib-venn==0.11.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.11.6)\n",
            "Requirement already satisfied: torch==1.8.1+cu101 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchsummary==1.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.5.1)\n",
            "Requirement already satisfied: torchtext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.9.1)\n",
            "Requirement already satisfied: torchvision==0.9.1+cu101 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.9.1+cu101)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from ecos==2.0.7.post1->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from googleapis-common-protos==1.53.0->-r requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile==0.10.3.post1->-r requirements.txt (line 9)) (1.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 11)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader==0.9.0->-r requirements.txt (line 12)) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader==0.9.0->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from pandas-gbq==0.13.3->-r requirements.txt (line 13)) (0.4.4)\n",
            "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.7/dist-packages (from pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pandas-gbq==0.13.3->-r requirements.txt (line 13)) (56.1.0)\n",
            "Requirement already satisfied: google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.21.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.7/dist-packages (from pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.30.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==1.4.1->-r requirements.txt (line 14)) (1.15.0)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==1.4.1->-r requirements.txt (line 14)) (2.11.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 16)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 16)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from matplotlib-inline==0.1.2->-r requirements.txt (line 17)) (5.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu101->-r requirements.txt (line 19)) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r requirements.txt (line 21)) (4.41.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu101->-r requirements.txt (line 22)) (7.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->-r requirements.txt (line 5)) (0.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 5)) (20.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile==0.10.3.post1->-r requirements.txt (line 9)) (2.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader==0.9.0->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader==0.9.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader==0.9.0->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader==0.9.0->-r requirements.txt (line 12)) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.0.3)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<2.0.0dev,>=0.6.0; extra == \"bqstorage\" in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.1.0)\n",
            "Requirement already satisfied: pyarrow!=0.14.0,>=0.13.0; extra == \"bqstorage\" in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (3.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (4.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.8->pandas-profiling==1.4.1->-r requirements.txt (line 14)) (2.0.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets->matplotlib-inline==0.1.2->-r requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (1.26.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq==0.13.3->-r requirements.txt (line 13)) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HjVRAHZaAHr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}